# OpenMLOps

Pipeline MLOps de bout en bout pour entra√Æner, √©valuer, versionner, monitorer et re-d√©clencher un entra√Ænement d‚Äôun mod√®le CNN sur CIFAR-10, en s‚Äôappuyant sur ZenML, MLflow, DVC et Evidently.

## üé• D√©monstration vid√©o

- Lien de la d√©mo: [Voir la vid√©o](https://drive.google.com/file/d/19AHxkMH7kOTWgu4__hy3lFixJjV5zxiP/view?usp=sharing)

## 1) Objectif du projet

Ce projet d√©montre un workflow MLOps complet orient√© production:

- ingestion de donn√©es versionn√©es (DVC),
- pipeline d‚Äôentra√Ænement orchestr√© (ZenML),
- tracking d‚Äôexp√©riences et registre de mod√®les (MLflow + PostgreSQL),
- g√©n√©ration de rapports de drift (Evidently),
- boucle de monitoring pouvant d√©clencher une logique de retrain.

Cas d‚Äôusage: base technique pour un MVP MLOps reproductible et extensible (CI/CD, registry policy, d√©ploiement, observabilit√©).

---

## 2) Stack technique

- **Orchestration pipeline**: ZenML `0.67.0`
- **Experiment tracking / Model Registry**: MLflow `2.12.1`
- **Versioning data**: DVC `3.50.1`
- **Drift monitoring**: Evidently `0.4.33`
- **DL framework**: PyTorch `2.3.1`
- **Data/ML libs**: NumPy, Pandas, scikit-learn, matplotlib, pyarrow
- **Object storage data**: MinIO (S3 compatible)
- **Infra locale**: Docker Compose (app + mlflow + postgres + minio)

---

## 3) Architecture fonctionnelle

### Pipeline entra√Ænement

`src/pipelines/training_pipeline.py`

1. `ingest_data`: `dvc pull` + v√©rification du dataset CIFAR-10.
2. `upload_data_to_minio`: upload du dataset vers MinIO.
3. `validate_data`: checks de forme / labels.
4. `split_data`: s√©paration train/val + test.
5. `preprocess`: reshape + normalisation + cr√©ation des DataLoader.
6. `train`: entra√Ænement CNN + logs MLflow.
7. `evaluate`: m√©triques + artifacts (matrice de confusion, report).
8. `register_model`: enregistrement dans le Model Registry MLflow.
9. `export_model`: export TorchScript.

### Pipeline monitoring

`src/pipelines/monitoring_pipeline.py`

1. `load_latest_model`: charge la derni√®re version enregistr√©e.
2. `collect_inference_data`: √©chantillonnage du test set + pr√©dictions.
3. `run_evidently_report`: rapport HTML/JSON de drift.
4. `trigger_decision`: d√©cision de retrain via `share_of_drifted_columns`.
5. `store_monitoring_artifacts`: push des rapports dans MLflow.

---

## 4) Arborescence (principale)

```text
docker-compose.yml
docker/Dockerfile
requirements.txt
src/
	pipelines/
		training_pipeline.py
		monitoring_pipeline.py
	steps/
		training/
		monitoring/
	utils/
data/
monitoring/
artifacts/
```

---

## 5) Variables de configuration

D√©finies dans `src/utils/settings.py` et/ou via environnement:

- `MLFLOW_TRACKING_URI` (d√©faut: `http://mlflow:5000`)
- `MLFLOW_EXPERIMENT_NAME` (d√©faut: `cifar10_cnn`)
- `SIMULATE_DRIFT` (`0` ou `1`)
- `MINIO_ENDPOINT_URL` (d√©faut: `http://minio:9000`)
- `MINIO_ACCESS_KEY` (d√©faut: `minioadmin`)
- `MINIO_SECRET_KEY` (d√©faut: `minioadmin`)
- `MINIO_BUCKET` (d√©faut: `dvc`)
- `MINIO_DATA_PREFIX` (d√©faut: `datasets/cifar10/raw`)
- `DATA_RAW_DIR` (d√©faut: `data/raw`)
- `MONITORING_DIR` (d√©faut: `monitoring`)
- `ARTIFACTS_DIR` (d√©faut: `artifacts`)
- `MODEL_NAME` (d√©faut: `cifar10_cnn`)

---

## 6) Pr√©requis

- Docker + Docker Compose
- (Optionnel) Python 3.13.2 + venv pour ex√©cuter hors conteneur

---

## 7) D√©marrage rapide (recommand√©: Docker)

### 7.1 Lancer les services

```bash
docker compose -f docker-compose.yml up -d --build
```

Services expos√©s:

- MLflow UI/API: `http://localhost:5000`
- ZenML Dashboard/API: `http://localhost:8237`
- PostgreSQL: `localhost:5432`
- MinIO API: `http://localhost:9000`
- MinIO Console: `http://localhost:9001`

Identifiants MinIO par d√©faut:

- User: `minioadmin`
- Password: `minioadmin`

### 7.2 Ex√©cuter le pipeline d‚Äôentra√Ænement

```bash
docker compose -f docker-compose.yml exec app bash -lc "python -m src.pipelines.training_pipeline"
```

### 7.3 Ex√©cuter le pipeline de monitoring (sans drift simul√©)

```bash
docker compose -f docker-compose.yml exec app bash -lc "python -m src.pipelines.monitoring_pipeline"
```

### 7.4 Ex√©cuter le monitoring avec drift simul√©

```bash
docker compose -f docker-compose.yml exec -e SIMULATE_DRIFT=1 app bash -lc "python -m src.pipelines.monitoring_pipeline"
```

### 7.5 Arr√™ter l‚Äôenvironnement

```bash
docker compose -f docker-compose.yml down
```

---

## 8) Ex√©cution locale (hors Docker)

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# .venv\Scripts\activate   # Windows PowerShell

pip install -r requirements.txt

python -m src.pipelines.training_pipeline
python -m src.pipelines.monitoring_pipeline
```

> En local, v√©rifie que `MLFLOW_TRACKING_URI` pointe vers une instance MLflow active.

---

## 9) Observabilit√© & artifacts

### MLflow

- Experiments: m√©triques d‚Äôentra√Ænement et de test.
- Model Registry: versions du mod√®le `cifar10_cnn`.
- Artifacts: rapport de classification, confusion matrix, rapports monitoring.

### Fichiers locaux

- `artifacts/model_torchscript.pt`
- `artifacts/confusion_matrix.png`
- `artifacts/classification_report.txt`
- `monitoring/evidently_report.html`
- `monitoring/evidently_report.json`
- `monitoring/inference.parquet`

---

## 10) Commandes utiles op√©rateur MLOps

### Ouvrir un shell dans l‚Äôapp

```bash
docker compose -f docker-compose.yml exec app bash
```

### Voir les logs MLflow

```bash
docker compose -f docker-compose.yml logs -f mlflow
```

### Voir les logs ZenML Server

```bash
docker compose -f docker-compose.yml logs -f zenml-server
```

### V√©rifier les containers

```bash
docker compose -f docker-compose.yml ps
```

---

## 11) D√©pannage

### Warning protobuf / mlflow

Le warning autour de `google.protobuf.service` est un avertissement de d√©pr√©ciation amont et ne bloque pas l‚Äôex√©cution du pipeline.

### Erreur ‚Äúmodel is not JSON serializable‚Äù (ZenML)

R√©solue dans cette base: le mod√®le est d√©sormais charg√© via une **step ZenML** (`load_latest_model`) et transmis comme artifact, pas comme param√®tre Python brut.

### Dataset introuvable

V√©rifie:

- la pr√©sence de `data/raw/cifar-10-batches-py`,
- la coh√©rence DVC (`dvc pull`),
- les volumes Docker mont√©s sur `/workspace`.

### MLflow vide (aucun run affich√©)

V√©rifie:

- que tu es bien dans l‚Äôexp√©rience `cifar10_cnn` (ou la valeur de `MLFLOW_EXPERIMENT_NAME`),
- que la page MLflow est rafra√Æchie (`http://localhost:5000`),
- que les pipelines ont √©t√© relanc√©s apr√®s les changements de logging.

---

## 12) Limites actuelles et √©volutions recommand√©es

- Ajouter des tests unitaires/int√©gration pour chaque step.
- Ajouter validation de sch√©ma/qualit√© de donn√©es (Great Expectations ou similaire).
- Industrialiser le trigger retrain (event-driven / scheduler / policy registry).
- Ajouter CI/CD (lint, tests, build image, pipeline smoke test).
- D√©ployer vers orchestrateur distant (Kubernetes + stack ZenML d√©di√©e).

---

## 13) √âtape 13 ‚Äî Ex√©cuter (les commandes)

Cette s√©quence permet de lancer l‚Äôinfrastructure, initialiser ZenML, ex√©cuter l‚Äôentra√Ænement, puis valider le monitoring avec et sans drift simul√©.

### 13.1 Lancer l‚Äôinfra (si pas d√©j√† fait)

```bash
docker compose -f docker-compose.yml up -d --build
```

### 13.2 Initialiser ZenML

```bash
docker compose -f docker-compose.yml exec app bash -lc "zenml init"
```

### 13.3 Ex√©cuter le pipeline d‚Äôentra√Ænement

```bash
docker compose -f docker-compose.yml exec app bash -lc "python -m src.pipelines.training_pipeline"
```

### 13.4 Ex√©cuter le pipeline de monitoring (sans drift)

```bash
docker compose -f docker-compose.yml exec app bash -lc "python -m src.pipelines.monitoring_pipeline"
```

### 13.5 Simuler un drift et d√©clencher la logique de retrain (d√©mo)

```bash
docker compose -f docker-compose.yml exec -e SIMULATE_DRIFT=1 app bash -lc "python -m src.pipelines.monitoring_pipeline"
```

> Note: dans ce d√©p√¥t, le fichier pr√©sent est `docker-compose.yml` √† la racine. Si vous ne disposez pas de `compose/docker-compose.yml`, utilisez `-f docker-compose.yml`.

---

## 14) Bonnes pratiques pour contribution

- Garder les steps **purs**, d√©terministes et idempotents.
- Typage explicite des entr√©es/sorties de steps pour compatibilit√© materializers.
- Traiter toute nouvelle d√©pendance au niveau `requirements.txt` + Dockerfile.
- Ne pas coupler logique m√©tier et configuration runtime (utiliser variables d‚Äôenvironnement).

---

## 15) R√©sum√© ex√©cutable (TL;DR)

```bash
# 1) Infra
docker compose -f docker-compose.yml up -d --build

# 2) Train
docker compose -f docker-compose.yml exec app bash -lc "python -m src.pipelines.training_pipeline"

# 3) Monitoring
docker compose -f docker-compose.yml exec app bash -lc "python -m src.pipelines.monitoring_pipeline"

# 4) Monitoring avec drift simul√©
docker compose -f docker-compose.yml exec -e SIMULATE_DRIFT=1 app bash -lc "python -m src.pipelines.monitoring_pipeline"
```

